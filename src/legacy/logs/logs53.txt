10/15/2023 23:17:16 - WARNING - __main__ - device: cuda:7, n_gpu: 8, 16-bits training: True
Using pad_token, but it is not set yet.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]
10/15/2023 23:18:59 - INFO - __main__ - Namespace(model_type='llama', model_name_or_path='meta-llama/Llama-2-13b-chat-hf', prompt='data9/original_data.txt', length=300, num_hidden_layers=None, stop_token=None, temperature=1.0, repetition_penalty=1.0, k=0, p=0, prefix='', suffix='', padding_text='', xlm_language='', seed=42, data_folder=42, no_cuda=False, stream_output=False, num_return_sequences=1, fp16=True, jit=False, device=device(type='cuda', index=7), n_gpu=8)
10/15/2023 23:18:59 - INFO - Unlimiformer - Encoding 0 to 39 out of 247
10/15/2023 23:18:59 - INFO - Unlimiformer - {"ed6eadff-2866-4fa0-a" : "7e1e246e-1381-4fe7-8"},
10/15/2023 23:19:05 - INFO - Unlimiformer - {"ed6eadff-2866-4fa0-a" : "7e1e246e-1381-4fe7-8"},
10/15/2023 23:19:05 - INFO - Unlimiformer - Encoding 39 to 81 out of 247
10/15/2023 23:19:05 - INFO - Unlimiformer - {"ABCD" : "EFGH"}, {"d55e2bf3-1796-4334-8" : "3bef29ab-3659-42b6-8"},
10/15/2023 23:19:08 - INFO - Unlimiformer - {"d55e2bf3-1796-4334-8" : "3bef29ab-3659-42b6-8"},
10/15/2023 23:19:08 - INFO - Unlimiformer - Encoding 81 to 123 out of 247
10/15/2023 23:19:08 - INFO - Unlimiformer - ,{"ABCD" : "EFGH"}, {"acc7b88f-2745-418a-9" : "ee1a9c8e-310e-4f5d-a"},
10/15/2023 23:19:12 - INFO - Unlimiformer - {"acc7b88f-2745-418a-9" : "ee1a9c8e-310e-4f5d-a"},
10/15/2023 23:19:12 - INFO - Unlimiformer - Encoding 123 to 166 out of 247
10/15/2023 23:19:12 - INFO - Unlimiformer - ,,{"ABCD" : "EFGH"}, {"2b3710e0-a8ac-4c6d-8" : "9ce19878-754b-47d3-9"},
10/15/2023 23:19:15 - INFO - Unlimiformer - {"2b3710e0-a8ac-4c6d-8" : "9ce19878-754b-47d3-9"},
10/15/2023 23:19:15 - INFO - Unlimiformer - Encoding 166 to 206 out of 247
10/15/2023 23:19:15 - INFO - Unlimiformer - ,,,{"ABCD" : "EFGH"}, {"4fd36e1b-80c4-45c5-9" : "e89ddcde-84bf-4da6-8"},
10/15/2023 23:19:18 - INFO - Unlimiformer - {"4fd36e1b-80c4-45c5-9" : "e89ddcde-84bf-4da6-8"},
10/15/2023 23:19:18 - INFO - Unlimiformer - Encoding 206 to 247 out of 247
10/15/2023 23:19:18 - INFO - Unlimiformer - ,,,,{"ABCD" : "EFGH"}, {"701c29e7-01ef-4d08-8" : "520ade86-5ed8-4093-a"}
10/15/2023 23:19:21 - INFO - Unlimiformer - {"701c29e7-01ef-4d08-8" : "520ade86-5ed8-4093-a"}
10/15/2023 23:19:21 - INFO - Unlimiformer - "Pre Forward Hook", <s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>[INST] <<SYS>>
You are a helpful assistant. Answer with short responses according to the question. 
<</SYS>>

, 280
10/15/2023 23:19:25 - INFO - Unlimiformer - "Pre Forward Hook", Based, 1
/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/faiss/contrib/torch_utils.py:44: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 2)
10/15/2023 23:19:47 - INFO - Unlimiformer - "Pre Forward Hook", on, 1
10/15/2023 23:20:05 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/15/2023 23:20:20 - INFO - Unlimiformer - "Pre Forward Hook", above, 1
10/15/2023 23:20:35 - INFO - Unlimiformer - "Pre Forward Hook", information, 1
10/15/2023 23:20:52 - INFO - Unlimiformer - "Pre Forward Hook", ,, 1
10/15/2023 23:21:06 - INFO - Unlimiformer - "Pre Forward Hook", can, 1
10/15/2023 23:21:22 - INFO - Unlimiformer - "Pre Forward Hook", you, 1
10/15/2023 23:21:39 - INFO - Unlimiformer - "Pre Forward Hook", tell, 1
10/15/2023 23:21:53 - INFO - Unlimiformer - "Pre Forward Hook", me, 1
10/15/2023 23:22:11 - INFO - Unlimiformer - "Pre Forward Hook", what, 1
10/15/2023 23:22:25 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/15/2023 23:22:41 - INFO - Unlimiformer - "Pre Forward Hook", value, 1
10/15/2023 23:22:57 - INFO - Unlimiformer - "Pre Forward Hook", is, 1
10/15/2023 23:23:10 - INFO - Unlimiformer - "Pre Forward Hook", for, 1
10/15/2023 23:23:26 - INFO - Unlimiformer - "Pre Forward Hook", ", 1
10/15/2023 23:23:43 - INFO - Unlimiformer - "Pre Forward Hook", 7, 1
10/15/2023 23:23:59 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:24:17 - INFO - Unlimiformer - "Pre Forward Hook", 1, 1
10/15/2023 23:24:32 - INFO - Unlimiformer - "Pre Forward Hook", c, 1
10/15/2023 23:24:47 - INFO - Unlimiformer - "Pre Forward Hook", 2, 1
10/15/2023 23:25:04 - INFO - Unlimiformer - "Pre Forward Hook", 9, 1
10/15/2023 23:25:19 - INFO - Unlimiformer - "Pre Forward Hook", e, 1
10/15/2023 23:25:38 - INFO - Unlimiformer - "Pre Forward Hook", 7, 1
10/15/2023 23:25:51 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:26:07 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:26:23 - INFO - Unlimiformer - "Pre Forward Hook", 1, 1
10/15/2023 23:26:39 - INFO - Unlimiformer - "Pre Forward Hook", ef, 1
10/15/2023 23:26:56 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:27:10 - INFO - Unlimiformer - "Pre Forward Hook", 4, 1
10/15/2023 23:27:25 - INFO - Unlimiformer - "Pre Forward Hook", d, 1
10/15/2023 23:27:41 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:27:57 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:28:13 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:28:28 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:28:44 - INFO - Unlimiformer - "Pre Forward Hook", "?, 1
10/15/2023 23:28:59 - INFO - Unlimiformer - "Pre Forward Hook", [, 1
10/15/2023 23:29:13 - INFO - Unlimiformer - "Pre Forward Hook", /, 1
10/15/2023 23:29:30 - INFO - Unlimiformer - "Pre Forward Hook", INST, 1
10/15/2023 23:29:45 - INFO - Unlimiformer - "Pre Forward Hook", ], 1
10/15/2023 23:30:00 - INFO - Unlimiformer - "Pre Forward Hook", , 1
10/15/2023 23:30:16 - INFO - Unlimiformer - "Pre Forward Hook", Sure, 1
10/15/2023 23:30:30 - INFO - Unlimiformer - "Pre Forward Hook", !, 1
10/15/2023 23:30:46 - INFO - Unlimiformer - "Pre Forward Hook", Based, 1
10/15/2023 23:31:00 - INFO - Unlimiformer - "Pre Forward Hook", on, 1
10/15/2023 23:31:14 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/15/2023 23:31:29 - INFO - Unlimiformer - "Pre Forward Hook", information, 1
10/15/2023 23:31:43 - INFO - Unlimiformer - "Pre Forward Hook", provided, 1
10/15/2023 23:31:57 - INFO - Unlimiformer - "Pre Forward Hook", ,, 1
10/15/2023 23:32:14 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/15/2023 23:32:28 - INFO - Unlimiformer - "Pre Forward Hook", value, 1
10/15/2023 23:32:43 - INFO - Unlimiformer - "Pre Forward Hook", for, 1
10/15/2023 23:32:58 - INFO - Unlimiformer - "Pre Forward Hook", ", 1
10/15/2023 23:33:12 - INFO - Unlimiformer - "Pre Forward Hook", 7, 1
10/15/2023 23:33:29 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:33:43 - INFO - Unlimiformer - "Pre Forward Hook", 1, 1
10/15/2023 23:33:57 - INFO - Unlimiformer - "Pre Forward Hook", c, 1
10/15/2023 23:34:12 - INFO - Unlimiformer - "Pre Forward Hook", 2, 1
10/15/2023 23:34:28 - INFO - Unlimiformer - "Pre Forward Hook", 9, 1
10/15/2023 23:34:45 - INFO - Unlimiformer - "Pre Forward Hook", e, 1
10/15/2023 23:35:01 - INFO - Unlimiformer - "Pre Forward Hook", 7, 1
10/15/2023 23:35:15 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:35:31 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:35:47 - INFO - Unlimiformer - "Pre Forward Hook", 1, 1
10/15/2023 23:36:04 - INFO - Unlimiformer - "Pre Forward Hook", ef, 1
10/15/2023 23:36:21 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:36:36 - INFO - Unlimiformer - "Pre Forward Hook", 4, 1
10/15/2023 23:36:52 - INFO - Unlimiformer - "Pre Forward Hook", d, 1
10/15/2023 23:37:07 - INFO - Unlimiformer - "Pre Forward Hook", 0, 1
10/15/2023 23:37:22 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:37:38 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:37:52 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:38:10 - INFO - Unlimiformer - "Pre Forward Hook", ", 1
10/15/2023 23:38:25 - INFO - Unlimiformer - "Pre Forward Hook", is, 1
10/15/2023 23:38:40 - INFO - Unlimiformer - "Pre Forward Hook", ", 1
10/15/2023 23:38:57 - INFO - Unlimiformer - "Pre Forward Hook", e, 1
10/15/2023 23:39:12 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:39:29 - INFO - Unlimiformer - "Pre Forward Hook", 9, 1
10/15/2023 23:39:46 - INFO - Unlimiformer - "Pre Forward Hook", dd, 1
10/15/2023 23:40:02 - INFO - Unlimiformer - "Pre Forward Hook", c, 1
10/15/2023 23:40:18 - INFO - Unlimiformer - "Pre Forward Hook", de, 1
10/15/2023 23:40:33 - INFO - Unlimiformer - "Pre Forward Hook", -, 1
10/15/2023 23:40:50 - INFO - Unlimiformer - "Pre Forward Hook", 8, 1
10/15/2023 23:41:06 - INFO - Unlimiformer - "Pre Forward Hook", 4, 1
10/15/2023 23:41:21 - INFO - Unlimiformer - "Pre Forward Hook", bf, 1
Traceback (most recent call last):
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/run_generation.py", line 583, in <module>
    main()
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/run_generation.py", line 534, in main
    output_sequences = model.generate(
                       ^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 694, in pre_generate_hook
    vals_pred.append(self.original_generate_func(input_ids_prefix, **new_kwargs))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/generation/utils.py", line 1648, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/generation/utils.py", line 2730, in sample
    outputs = self(
              ^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 779, in pre_forward_hook
    result = self.original_forward_func(input_ids=input_ids, labels=labels, attention_mask=attention_mask, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 820, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 708, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 424, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 825, in attention_pre_forward_hook
    result = original_cross_attn_forward_func(hidden_states=hidden_states, attention_mask=attention_mask, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 321, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1547, in _call_impl
    hook_result = hook(self, args, result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 963, in attention_forward_hook
    retrieved_keys, retrieved_values = self.post_process_retrieved(embeddings, k_proj_layer, v_proj_layer, top_search_key_indices)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 1395, in post_process_retrieved
    retrieved_values = torch.matmul(embeddings, v_weight) + v_bias # (beam, head, encoder_len, embed_dim)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
