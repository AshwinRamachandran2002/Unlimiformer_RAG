10/16/2023 12:50:27 - WARNING - __main__ - device: cuda:3, n_gpu: 8, 16-bits training: True
Using pad_token, but it is not set yet.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]
10/16/2023 12:52:13 - INFO - __main__ - Namespace(model_type='llama', model_name_or_path='meta-llama/Llama-2-13b-chat-hf', prompt='data11/original_data.txt', length=300, num_hidden_layers=None, stop_token=None, temperature=1.0, repetition_penalty=1.0, k=0, p=0, prefix='', suffix='', padding_text='', xlm_language='', seed=42, data_folder=42, no_cuda=False, stream_output=False, num_return_sequences=1, fp16=True, jit=False, device=device(type='cuda', index=3), n_gpu=8)
10/16/2023 12:52:13 - INFO - Unlimiformer - Encoding 0 to 6 out of 18
10/16/2023 12:52:13 - INFO - Unlimiformer - Williamson is baking,
10/16/2023 12:52:14 - INFO - Unlimiformer - Williamson is baking,
10/16/2023 12:52:14 - INFO - Unlimiformer - Encoding 6 to 13 out of 18
10/16/2023 12:52:14 - INFO - Unlimiformer - Williamson is baking, Oppenheimer is cycling,
10/16/2023 12:52:14 - INFO - Unlimiformer - Oppenheimer is cycling,
10/16/2023 12:52:14 - INFO - Unlimiformer - Encoding 13 to 18 out of 18
10/16/2023 12:52:14 - INFO - Unlimiformer - A, Williamson is baking, Leechenbaum is painting
10/16/2023 12:52:14 - INFO - Unlimiformer - Leechenbaum is painting
10/16/2023 12:52:14 - INFO - Unlimiformer - "Pre Forward Hook", <s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>[INST] <<SYS>>
You are a helpful assistant. Answer with short responses according to the question. 
<</SYS>>

, 51
10/16/2023 12:52:14 - INFO - Unlimiformer - "Pre Forward Hook", Based, 1
10/16/2023 12:52:14 - INFO - Unlimiformer - "Pre Forward Hook", on, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", above, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", information, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", ,, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", can, 1
10/16/2023 12:52:15 - INFO - Unlimiformer - "Pre Forward Hook", you, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", tell, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", me, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", what, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", O, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", ppen, 1
10/16/2023 12:52:16 - INFO - Unlimiformer - "Pre Forward Hook", heimer, 1
10/16/2023 12:52:17 - INFO - Unlimiformer - "Pre Forward Hook", is, 1
10/16/2023 12:52:17 - INFO - Unlimiformer - "Pre Forward Hook", doing, 1
10/16/2023 12:52:17 - INFO - Unlimiformer - "Pre Forward Hook", ?, 1
10/16/2023 12:52:17 - INFO - Unlimiformer - "Pre Forward Hook", [, 1
10/16/2023 12:52:17 - INFO - Unlimiformer - "Pre Forward Hook", /, 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", INST, 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", ], 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", , 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", Sure, 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", !, 1
10/16/2023 12:52:18 - INFO - Unlimiformer - "Pre Forward Hook", Based, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", on, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", information, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", provided, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", ,, 1
10/16/2023 12:52:19 - INFO - Unlimiformer - "Pre Forward Hook", O, 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", ppen, 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", heimer, 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", is, 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", painting, 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", ., 1
10/16/2023 12:52:20 - INFO - Unlimiformer - "Pre Forward Hook", <s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>[INST] <<SYS>>
You are a helpful assistant. Answer with short responses according to the question. 
<</SYS>>

, 51
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", Based, 1
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", on, 1
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", the, 1
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", above, 1
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", information, 1
10/16/2023 12:52:21 - INFO - Unlimiformer - "Pre Forward Hook", ,, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", can, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", you, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", tell, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", me, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", what, 1
10/16/2023 12:52:22 - INFO - Unlimiformer - "Pre Forward Hook", William, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", son, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", is, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", doing, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", ?, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", [, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", /, 1
10/16/2023 12:52:23 - INFO - Unlimiformer - "Pre Forward Hook", INST, 1
Traceback (most recent call last):
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/run_generation.py", line 583, in <module>
    main()
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/run_generation.py", line 534, in main
    output_sequences = model.generate(
                       ^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 723, in pre_generate_hook
    vals_pred.append(self.original_generate_func(input_ids_prefix, **new_kwargs))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/generation/utils.py", line 1648, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/generation/utils.py", line 2730, in sample
    outputs = self(
              ^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/RoPE/unlimiformer/src/unlimiformer.py", line 808, in pre_forward_hook
    result = self.original_forward_func(input_ids=input_ids, labels=labels, attention_mask=attention_mask, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 820, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 708, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/raid/infolab/ashwinr/anaconda3/envs/btp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
